{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "table = pd.read_table('./1663769555_8559356_train.txt', names=['binding','sequence'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def return_binary_vectorized_form(data_frame, feat = None):\n",
    "    if feat is None:\n",
    "        count_vectorizer = CountVectorizer(binary=True)\n",
    "    else:\n",
    "        count_vectorizer = CountVectorizer(binary=True, vocabulary=feat)\n",
    "    fitted_and_transformed = count_vectorizer.fit_transform(data_frame).toarray()\n",
    "    return count_vectorizer,  fitted_and_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "def select_k_best_features(feature_set, target_values, fraction, feature_list):\n",
    "    select_bestselect_best = SelectKBest(score_func=chi2, k = int(len(feature_list)*fraction))\n",
    "    select_bestselect_best.fit(feature_set,target_values)\n",
    "    mask = select_bestselect_best.get_support()\n",
    "    k_best_featurs = feature_list[mask]\n",
    "    return k_best_featurs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "active_df = table.loc[table.binding == 1]\n",
    "not_active_df = table.loc[table.binding == 0]\n",
    "# Mainly spliting the data here for testing, that is the reason train size is set to .20\n",
    "active_train, active_test, active_binding_train, active_binding_test = train_test_split(active_df.sequence, active_df.binding, shuffle=True, train_size= .80)\n",
    "not_active_train, not_active_test, not_active_binding_train, not_active_binding_test = train_test_split(not_active_df.sequence, not_active_df.binding, shuffle=True, train_size=.90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def createDf(data):\n",
    "    pd_df = pd.DataFrame(data)\n",
    "    return pd_df\n",
    "def addColumn(copy_to, copy_from ,cname):\n",
    "    copy_to[cname] = copy_from[cname]\n",
    "    return copy_to"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    649\n",
      "1     62\n",
      "Name: binding, dtype: int64\n",
      "0    73\n",
      "1    16\n",
      "Name: binding, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "active_test_df = pd.DataFrame(active_test)\n",
    "active_binding_test_df = pd.DataFrame(active_binding_test)\n",
    "active_test_df['binding'] = active_binding_test_df['binding']\n",
    "not_active_test_df = pd.DataFrame(not_active_test)\n",
    "not_active_binding_test_df = pd.DataFrame(not_active_binding_test)\n",
    "not_active_test_df['binding'] = not_active_binding_test_df['binding']\n",
    "active_train_df = createDf(active_train)\n",
    "active_binding_train_df = createDf(active_binding_train)\n",
    "active_train_df = addColumn(active_train_df, active_binding_train_df, 'binding')\n",
    "not_active_train_df = createDf(not_active_train)\n",
    "not_active_binding_train_df = createDf(not_active_binding_train)\n",
    "not_active_train_df = addColumn(not_active_train_df, not_active_binding_train_df, 'binding')\n",
    "train_df = pd.concat([active_train_df, not_active_train_df]).reset_index()\n",
    "train_df = train_df.drop('index', axis=1)\n",
    "print(train_df.binding.value_counts())\n",
    "test_df = pd.concat([active_test_df, not_active_test_df]).reset_index()\n",
    "test_df = test_df.drop('index', axis=1)\n",
    "print(test_df.binding.value_counts())\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "sampler = RandomOverSampler(sampling_strategy=.90)\n",
    "x_sampled, y_sampled = sampler.fit_resample(np.array(train_df.sequence).reshape(-1, 1), train_df.binding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    649\n",
      "1    584\n",
      "Name: binding, dtype: int64\n",
      "0    73\n",
      "1    16\n",
      "Name: binding, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_train_set = pd.DataFrame(x_sampled, columns  =[\"sequence\"])\n",
    "final_train_set['binding'] = y_sampled\n",
    "print(final_train_set.binding.value_counts())\n",
    "\n",
    "final_test_set = pd.DataFrame(test_df.sequence, columns  =[\"sequence\"])\n",
    "final_test_set['binding'] = test_df.binding\n",
    "print(final_test_set.binding.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_result = np.array(final_train_set.binding)\n",
    "test_result = np.array(final_test_set.binding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "vectorizer_best, training_split = return_binary_vectorized_form(final_train_set.sequence)\n",
    "test_split = vectorizer_best.transform(final_test_set.sequence).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1233, 82184)\n",
      "(89, 82184)\n"
     ]
    }
   ],
   "source": [
    "print(training_split.shape)\n",
    "print(test_split.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['10000', '10001', '10008', ..., '99962', '99972', '9998'],\n      dtype=object)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = select_k_best_features(training_split,train_result,.30,vectorizer_best.get_feature_names_out())\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "vectorizer_best, training_split = return_binary_vectorized_form(final_train_set.sequence,features)\n",
    "test_split = vectorizer_best.transform(final_test_set.sequence).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "initial_weight = np.ones(training_split.shape[0])*(1/training_split.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def updateWeight(missmatch, weight, alpha):\n",
    "    mi = 0\n",
    "    missmatch_size = len(missmatch)\n",
    "    wi = 0\n",
    "\n",
    "    new_weight = []\n",
    "    norm_constant = 0\n",
    "    while wi < len(weight):\n",
    "        if mi < missmatch_size and missmatch[mi] == wi:\n",
    "            k = weight[wi] * math.exp(alpha)\n",
    "            mi+=1\n",
    "        else:\n",
    "            k = weight[wi] * math.exp(-1*alpha)\n",
    "        new_weight.append( k )\n",
    "        norm_constant += k\n",
    "        wi += 1\n",
    "\n",
    "    new_weight /= norm_constant\n",
    "    sum =0\n",
    "    for i in new_weight:\n",
    "        sum+=i\n",
    "    print(sum)\n",
    "    # plt.plot(new_weight)\n",
    "    # plt.show()\n",
    "    return new_weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "def findMissClassificatonIndex(predicted, test_res, weight):\n",
    "    error_rate = 0\n",
    "    missmatch_indexes = []\n",
    "    incorrect= []\n",
    "    tn, fp, fn, tp = confusion_matrix(test_res, predicted).ravel()\n",
    "    precision = tp / (tp+ fp)\n",
    "    recall = tp / (tp+ fn)\n",
    "    score = (2 * precision * recall) / (precision + recall)\n",
    "    print(score)\n",
    "    print(accuracy_score(test_res, predicted))\n",
    "    for i, (pred, real) in enumerate(zip(predicted, test_res)):\n",
    "        if pred != real:\n",
    "            incorrect.append((i, pred, real))\n",
    "            missmatch_indexes.append(i)\n",
    "            error_rate += weight[i]\n",
    "    error_rate /= len(predicted)\n",
    "    # print(incorrect)\n",
    "    return error_rate, missmatch_indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def rejectionSampling(train_data, train_res, weights):\n",
    "    samplesize  = int(4 * len(train_data))\n",
    "    new_train_data = []\n",
    "    new_train_res = []\n",
    "    new_weights = []\n",
    "    adding_index =[]\n",
    "    max_w = max(weights)\n",
    "\n",
    "    for i in range(samplesize):\n",
    "        while True:\n",
    "            index = random.randrange(len(weights))\n",
    "            u = max_w * random.random()\n",
    "            if u <= weights[index]:\n",
    "                new_train_data.append(train_data[index])\n",
    "                new_train_res.append(train_res[index])\n",
    "                adding_index.append(index)\n",
    "                break\n",
    "    # print(adding_index)\n",
    "    return np.array(new_train_data), np.array(new_train_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "def resample(train_data, train_res, weights):\n",
    "    size = len(train_data)\n",
    "    indexes = np.random.choice(int(size), int( 5 * size), replace=True, p=weights)\n",
    "    new_train_data = []\n",
    "    new_train_res = []\n",
    "    for index in indexes:\n",
    "         new_train_data.append(train_data[index])\n",
    "         new_train_res.append(train_res[index])\n",
    "    return np.array(new_train_data), np.array(new_train_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "class EarlyStoppingMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(EarlyStoppingMonitor, self).__init__()\n",
    "        self.f1_train = None\n",
    "        self.f1_test = None\n",
    "        self.prevous = None\n",
    "        self.count =0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_train_precision = logs.get('precision')\n",
    "        current_train_recall= logs.get('recall')\n",
    "\n",
    "        if current_train_precision==0 or current_train_recall==0:\n",
    "            print(\"**** Waring: precision recall zero avoid exception ****\")\n",
    "            return\n",
    "        self.f1_train = (2*current_train_precision*current_train_recall) / (current_train_precision+current_train_recall)\n",
    "        if self.prevous == None:\n",
    "            self.prevous = self.f1_train\n",
    "        if self.prevous == self.f1_train:\n",
    "            self.count += 1\n",
    "        else:\n",
    "            self.prevous = self.f1_train\n",
    "            self.count = 0\n",
    "        if self.count == 5:\n",
    "            self.model.stop_training = True\n",
    "            print('\\n\\n******* No improvements *******')\n",
    "        if current_train_recall > .70 and self.f1_train > .70:\n",
    "            # self.count += 1\n",
    "            # if self.count >4:\n",
    "            self.model.stop_training = True\n",
    "            print('\\n\\n******* Stoping on Defined Thresold *******')\n",
    "            print('F1 TRAINING: ', self.f1_train)\n",
    "            print('Recall TRAINING: ', current_train_recall)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.model.stop_training:\n",
    "            print(\"\\n\\n\\n****** Early Stopping *******\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def createBaseModel():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(training_split.shape[-1],)),\n",
    "        tf.keras.layers.Dense(2, activation='relu',kernel_regularizer=tf.keras.regularizers.L1(.015)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(), metrics=METRICS, optimizer='adam')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "ensemble_size = 12\n",
    "ensemble = []\n",
    "alphas = []\n",
    "def boosting(weights):\n",
    "\n",
    "    for i in range(ensemble_size):\n",
    "        print(\" =========== iteration ===========>:\", i )\n",
    "        train_data, train_res = resample(training_split, train_result, weights)\n",
    "        model = createBaseModel()\n",
    "        num_epochs = 60\n",
    "        print( \"bfore traning: \", ((sum(train_res)/len(train_res)))*100)\n",
    "        history = model.fit(train_data, train_res,\n",
    "                    epochs= num_epochs,\n",
    "                    batch_size=70,\n",
    "                    callbacks=[EarlyStoppingMonitor()])\n",
    "        predicted_result = model.predict(training_split)\n",
    "        predicted_result = [1 if i>=.5 else 0 for i in predicted_result ]\n",
    "        error_rate, error_indexes = findMissClassificatonIndex(predicted_result, train_result, weights)\n",
    "        print(\"error_rate:\", error_rate)\n",
    "\n",
    "        if error_rate > .5:\n",
    "            weights = np.ones(training_split.shape[0]) * (1/training_split.shape[0])\n",
    "            print(\"re-balancing and training because error:\", error_rate)\n",
    "            continue\n",
    "\n",
    "        amount_of_say = 0.2 * ( math.log( (1-error_rate) / error_rate ) )\n",
    "        alphas.append(amount_of_say)\n",
    "        ensemble.append(model)\n",
    "        weights = updateWeight(error_indexes, weights, amount_of_say)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " =========== iteration ===========>: 0\n",
      "bfore traning:  47.81832927818329\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:51:56.439815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6693 - tp: 2315.0000 - fp: 371.0000 - tn: 2846.0000 - fn: 633.0000 - precision: 0.8619 - recall: 0.7853\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8217962444592618\n",
      "Recall TRAINING:  0.7852781414985657\n",
      "89/89 [==============================] - 3s 24ms/step - loss: 0.6693 - tp: 2315.0000 - fp: 371.0000 - tn: 2846.0000 - fn: 633.0000 - precision: 0.8619 - recall: 0.7853\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:51:59.455332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81640625\n",
      "0.8475263584752636\n",
      "error_rate: 0.0001236606987224139\n",
      "1.0000000000000058\n",
      " =========== iteration ===========>: 1\n",
      "bfore traning:  82.43309002433091\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:00.263729: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6705 - tp: 4818.0000 - fp: 919.0000 - tn: 164.0000 - fn: 264.0000 - precision: 0.8398 - recall: 0.9481\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8906553433219584\n",
      "Recall TRAINING:  0.9480519890785217\n",
      "89/89 [==============================] - 3s 22ms/step - loss: 0.6705 - tp: 4818.0000 - fp: 919.0000 - tn: 164.0000 - fn: 264.0000 - precision: 0.8398 - recall: 0.9481\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:03.157058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428178315905339\n",
      "0.47364152473641524\n",
      "error_rate: 0.00014659475409723962\n",
      "0.9999999999999551\n",
      " =========== iteration ===========>: 2\n",
      "bfore traning:  12.635847526358477\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:03.923059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6642 - tp: 62.0000 - fp: 153.0000 - tn: 5233.0000 - fn: 717.0000 - precision: 0.2884 - recall: 0.0796\n",
      "Epoch 2/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1802 - tp: 3.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 776.0000 - precision: 1.0000 - recall: 0.0039\n",
      "Epoch 3/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1652 - tp: 2.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 777.0000 - precision: 1.0000 - recall: 0.0026\n",
      "Epoch 4/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1601 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 779.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1601 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 779.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1577 - tp: 6.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 773.0000 - precision: 1.0000 - recall: 0.0077\n",
      "Epoch 6/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1512 - tp: 1.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 778.0000 - precision: 1.0000 - recall: 0.0013\n",
      "Epoch 7/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1508 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5261.0000 - fn: 759.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1510 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 779.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1524 - tp: 11.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 768.0000 - precision: 1.0000 - recall: 0.0141\n",
      "Epoch 9/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1522 - tp: 8.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 771.0000 - precision: 1.0000 - recall: 0.0103\n",
      "Epoch 10/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1550 - tp: 15.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 764.0000 - precision: 1.0000 - recall: 0.0193\n",
      "Epoch 11/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1523 - tp: 27.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 752.0000 - precision: 1.0000 - recall: 0.0347\n",
      "Epoch 12/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1848 - tp: 40.0000 - fp: 2.0000 - tn: 5384.0000 - fn: 739.0000 - precision: 0.9524 - recall: 0.0513\n",
      "Epoch 13/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1490 - tp: 35.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 744.0000 - precision: 1.0000 - recall: 0.0449\n",
      "Epoch 14/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1465 - tp: 51.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 728.0000 - precision: 1.0000 - recall: 0.0655\n",
      "Epoch 15/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1482 - tp: 91.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 688.0000 - precision: 1.0000 - recall: 0.1168\n",
      "Epoch 16/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1420 - tp: 162.0000 - fp: 0.0000e+00 - tn: 5386.0000 - fn: 617.0000 - precision: 1.0000 - recall: 0.2080\n",
      "Epoch 17/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1406 - tp: 184.0000 - fp: 2.0000 - tn: 5384.0000 - fn: 595.0000 - precision: 0.9892 - recall: 0.2362\n",
      "Epoch 18/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1435 - tp: 252.0000 - fp: 3.0000 - tn: 5383.0000 - fn: 527.0000 - precision: 0.9882 - recall: 0.3235\n",
      "Epoch 19/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1354 - tp: 339.0000 - fp: 5.0000 - tn: 5381.0000 - fn: 440.0000 - precision: 0.9855 - recall: 0.4352\n",
      "Epoch 20/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1325 - tp: 421.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 358.0000 - precision: 0.9836 - recall: 0.5404\n",
      "Epoch 21/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1306 - tp: 441.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 338.0000 - precision: 0.9844 - recall: 0.5661\n",
      "Epoch 22/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1361 - tp: 428.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 351.0000 - precision: 0.9839 - recall: 0.5494\n",
      "Epoch 23/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1278 - tp: 495.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 284.0000 - precision: 0.9861 - recall: 0.6354\n",
      "Epoch 24/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1319 - tp: 509.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 270.0000 - precision: 0.9864 - recall: 0.6534\n",
      "Epoch 25/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1345 - tp: 539.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 240.0000 - precision: 0.9872 - recall: 0.6919\n",
      "Epoch 26/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1297 - tp: 530.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 249.0000 - precision: 0.9870 - recall: 0.6804\n",
      "Epoch 27/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1266 - tp: 590.0000 - fp: 7.0000 - tn: 5249.0000 - fn: 174.0000 - precision: 0.9883 - recall: 0.7723\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8649819649887374\n",
      "Recall TRAINING:  0.7689345479011536\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1264 - tp: 599.0000 - fp: 7.0000 - tn: 5379.0000 - fn: 180.0000 - precision: 0.9884 - recall: 0.7689\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:33.396046: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4204851752021563\n",
      "0.6512570965125709\n",
      "error_rate: 3.174471499036416e-05\n",
      "0.9999999999999994\n",
      " =========== iteration ===========>: 3\n",
      "bfore traning:  70.73803730738038\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:34.147486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6648 - tp: 4244.0000 - fp: 833.0000 - tn: 971.0000 - fn: 117.0000 - precision: 0.8359 - recall: 0.9732\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8993431070935025\n",
      "Recall TRAINING:  0.9731712937355042\n",
      "89/89 [==============================] - 3s 22ms/step - loss: 0.6648 - tp: 4244.0000 - fp: 833.0000 - tn: 971.0000 - fn: 117.0000 - precision: 0.8359 - recall: 0.9732\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:36.959837: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428178315905339\n",
      "0.47364152473641524\n",
      "error_rate: 0.00022705708326612315\n",
      "0.9999999999999772\n",
      " =========== iteration ===========>: 4\n",
      "bfore traning:  8.6455798864558\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:37.773294: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6618 - tp: 178.0000 - fp: 106.0000 - tn: 5526.0000 - fn: 355.0000 - precision: 0.6268 - recall: 0.3340\n",
      "Epoch 2/60\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1672 - tp: 11.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 522.0000 - precision: 1.0000 - recall: 0.0206\n",
      "Epoch 3/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1514 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 533.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1514 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 533.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1416 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 533.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1416 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 533.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1345 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5439.0000 - fn: 511.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1344 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 533.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/60\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1286 - tp: 50.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 483.0000 - precision: 1.0000 - recall: 0.0938\n",
      "Epoch 7/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1240 - tp: 18.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 515.0000 - precision: 1.0000 - recall: 0.0338\n",
      "Epoch 8/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1198 - tp: 186.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 347.0000 - precision: 1.0000 - recall: 0.3490\n",
      "Epoch 9/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1172 - tp: 220.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 313.0000 - precision: 1.0000 - recall: 0.4128\n",
      "Epoch 10/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1136 - tp: 262.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 271.0000 - precision: 1.0000 - recall: 0.4916\n",
      "Epoch 11/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1131 - tp: 280.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 253.0000 - precision: 1.0000 - recall: 0.5253\n",
      "Epoch 12/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1115 - tp: 294.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 239.0000 - precision: 1.0000 - recall: 0.5516\n",
      "Epoch 13/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1115 - tp: 315.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 218.0000 - precision: 1.0000 - recall: 0.5910\n",
      "Epoch 14/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1088 - tp: 310.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 223.0000 - precision: 1.0000 - recall: 0.5816\n",
      "Epoch 15/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1157 - tp: 374.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 159.0000 - precision: 1.0000 - recall: 0.7017\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8246967838003733\n",
      "Recall TRAINING:  0.7016885280609131\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1157 - tp: 374.0000 - fp: 0.0000e+00 - tn: 5632.0000 - fn: 159.0000 - precision: 1.0000 - recall: 0.7017\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:55.712695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1282051282051282\n",
      "0.5587996755879967\n",
      "error_rate: 2.174483321008233e-05\n",
      "1.0000000000000049\n",
      " =========== iteration ===========>: 5\n",
      "bfore traning:  67.20194647201947\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:56.542694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6582 - tp: 4015.0000 - fp: 1775.0000 - tn: 247.0000 - fn: 128.0000 - precision: 0.6934 - recall: 0.9691\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8084164085291426\n",
      "Recall TRAINING:  0.969104528427124\n",
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6582 - tp: 4015.0000 - fp: 1775.0000 - tn: 247.0000 - fn: 128.0000 - precision: 0.6934 - recall: 0.9691\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:52:59.431412: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6431718061674009\n",
      "0.4744525547445255\n",
      "error_rate: 0.00025314389298742505\n",
      "0.9999999999999782\n",
      " =========== iteration ===========>: 6\n",
      "bfore traning:  7.948094079480941\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:53:00.281440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6645 - tp: 11.0000 - fp: 121.0000 - tn: 5554.0000 - fn: 479.0000 - precision: 0.0833 - recall: 0.0224\n",
      "Epoch 2/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1587 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1587 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1363 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1363 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1307 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5538.0000 - fn: 482.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1304 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/60\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.1260 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5672.0000 - fn: 488.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1261 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1252 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1252 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1226 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5544.0000 - fn: 476.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1229 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1237 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5536.0000 - fn: 484.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1232 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5540.0000 - fn: 480.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1222 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5547.0000 - fn: 473.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1221 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1220 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5541.0000 - fn: 479.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1219 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1213 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5547.0000 - fn: 473.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1217 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 490.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1237 - tp: 18.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 472.0000 - precision: 1.0000 - recall: 0.0367\n",
      "Epoch 17/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1245 - tp: 30.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 460.0000 - precision: 1.0000 - recall: 0.0612\n",
      "Epoch 18/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1240 - tp: 79.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 411.0000 - precision: 1.0000 - recall: 0.1612\n",
      "Epoch 19/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1248 - tp: 149.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 341.0000 - precision: 1.0000 - recall: 0.3041\n",
      "Epoch 20/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1225 - tp: 168.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 322.0000 - precision: 1.0000 - recall: 0.3429\n",
      "Epoch 21/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1244 - tp: 172.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 318.0000 - precision: 1.0000 - recall: 0.3510\n",
      "Epoch 22/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1207 - tp: 168.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 322.0000 - precision: 1.0000 - recall: 0.3429\n",
      "Epoch 23/60\n",
      "89/89 [==============================] - 1s 11ms/step - loss: 0.1190 - tp: 168.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 322.0000 - precision: 1.0000 - recall: 0.3429\n",
      "Epoch 24/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1188 - tp: 169.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 321.0000 - precision: 1.0000 - recall: 0.3449\n",
      "Epoch 25/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1198 - tp: 182.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 308.0000 - precision: 1.0000 - recall: 0.3714\n",
      "Epoch 26/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1195 - tp: 186.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 304.0000 - precision: 1.0000 - recall: 0.3796\n",
      "Epoch 27/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1191 - tp: 200.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 290.0000 - precision: 1.0000 - recall: 0.4082\n",
      "Epoch 28/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1173 - tp: 201.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 289.0000 - precision: 1.0000 - recall: 0.4102\n",
      "Epoch 29/60\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1171 - tp: 208.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 282.0000 - precision: 1.0000 - recall: 0.4245\n",
      "Epoch 30/60\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1163 - tp: 213.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 277.0000 - precision: 1.0000 - recall: 0.4347\n",
      "Epoch 31/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1151 - tp: 211.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 279.0000 - precision: 1.0000 - recall: 0.4306\n",
      "Epoch 32/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1164 - tp: 215.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 275.0000 - precision: 1.0000 - recall: 0.4388\n",
      "Epoch 33/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1423 - tp: 239.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 251.0000 - precision: 1.0000 - recall: 0.4878\n",
      "Epoch 34/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1167 - tp: 219.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 271.0000 - precision: 1.0000 - recall: 0.4469\n",
      "Epoch 35/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1252 - tp: 221.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 269.0000 - precision: 1.0000 - recall: 0.4510\n",
      "Epoch 36/60\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1162 - tp: 221.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 269.0000 - precision: 1.0000 - recall: 0.4510\n",
      "Epoch 37/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1316 - tp: 251.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 239.0000 - precision: 1.0000 - recall: 0.5122\n",
      "Epoch 38/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1157 - tp: 228.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 262.0000 - precision: 1.0000 - recall: 0.4653\n",
      "Epoch 39/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1144 - tp: 223.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 267.0000 - precision: 1.0000 - recall: 0.4551\n",
      "Epoch 40/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1156 - tp: 230.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 260.0000 - precision: 1.0000 - recall: 0.4694\n",
      "Epoch 41/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1160 - tp: 234.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 256.0000 - precision: 1.0000 - recall: 0.4776\n",
      "Epoch 42/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1126 - tp: 233.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 257.0000 - precision: 1.0000 - recall: 0.4755\n",
      "Epoch 43/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1141 - tp: 246.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 244.0000 - precision: 1.0000 - recall: 0.5020\n",
      "Epoch 44/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1180 - tp: 234.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 256.0000 - precision: 1.0000 - recall: 0.4776\n",
      "Epoch 45/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1129 - tp: 245.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 245.0000 - precision: 1.0000 - recall: 0.5000\n",
      "Epoch 46/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1270 - tp: 291.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 199.0000 - precision: 1.0000 - recall: 0.5939\n",
      "Epoch 47/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1133 - tp: 248.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 242.0000 - precision: 1.0000 - recall: 0.5061\n",
      "Epoch 48/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1226 - tp: 268.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 222.0000 - precision: 1.0000 - recall: 0.5469\n",
      "Epoch 49/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1154 - tp: 259.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 231.0000 - precision: 1.0000 - recall: 0.5286\n",
      "Epoch 50/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1113 - tp: 261.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 229.0000 - precision: 1.0000 - recall: 0.5327\n",
      "Epoch 51/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1383 - tp: 280.0000 - fp: 4.0000 - tn: 5671.0000 - fn: 210.0000 - precision: 0.9859 - recall: 0.5714\n",
      "Epoch 52/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1159 - tp: 260.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 230.0000 - precision: 1.0000 - recall: 0.5306\n",
      "Epoch 53/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1154 - tp: 269.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 221.0000 - precision: 1.0000 - recall: 0.5490\n",
      "Epoch 54/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1128 - tp: 274.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 216.0000 - precision: 1.0000 - recall: 0.5592\n",
      "Epoch 55/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1125 - tp: 280.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 210.0000 - precision: 1.0000 - recall: 0.5714\n",
      "Epoch 56/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1150 - tp: 285.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 205.0000 - precision: 1.0000 - recall: 0.5816\n",
      "Epoch 57/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1118 - tp: 280.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 210.0000 - precision: 1.0000 - recall: 0.5714\n",
      "Epoch 58/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1146 - tp: 294.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 196.0000 - precision: 1.0000 - recall: 0.6000\n",
      "Epoch 59/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1220 - tp: 305.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 185.0000 - precision: 1.0000 - recall: 0.6224\n",
      "Epoch 60/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1140 - tp: 287.0000 - fp: 0.0000e+00 - tn: 5675.0000 - fn: 203.0000 - precision: 1.0000 - recall: 0.5857\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:54:05.824143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4712041884816754\n",
      "0.6723438767234388\n",
      "error_rate: 2.467843396768311e-05\n",
      "1.0000000000000058\n",
      " =========== iteration ===========>: 7\n",
      "bfore traning:  69.97566909975669\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:54:06.621842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6617 - tp: 4299.0000 - fp: 1847.0000 - tn: 4.0000 - fn: 15.0000 - precision: 0.6995 - recall: 0.9965\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8219885160792348\n",
      "Recall TRAINING:  0.9965229034423828\n",
      "89/89 [==============================] - 3s 24ms/step - loss: 0.6617 - tp: 4299.0000 - fp: 1847.0000 - tn: 4.0000 - fn: 15.0000 - precision: 0.6995 - recall: 0.9965\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:54:09.617606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428178315905339\n",
      "0.47364152473641524\n",
      "error_rate: 0.0002429999067345097\n",
      "1.0000000000000027\n",
      " =========== iteration ===========>: 8\n",
      "bfore traning:  7.477696674776967\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:54:10.421633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 3s 24ms/step - loss: 0.6436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1577 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1577 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1412 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5571.0000 - fn: 449.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1273 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1273 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1267 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1267 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1264 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5572.0000 - fn: 448.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1267 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1271 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5569.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1269 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1266 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1266 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1272 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1278 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5566.0000 - fn: 454.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1274 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5508.0000 - fn: 442.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1270 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5567.0000 - fn: 453.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1294 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1280 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5572.0000 - fn: 448.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1337 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5568.0000 - fn: 452.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1334 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1274 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5572.0000 - fn: 448.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1278 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5500.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1303 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1279 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5565.0000 - fn: 455.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1276 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 20/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5503.0000 - fn: 447.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 21/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1308 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5499.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5567.0000 - fn: 453.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1406 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 23/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1278 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5569.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1277 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 24/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5570.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1292 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 25/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1274 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5579.0000 - fn: 441.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5571.0000 - fn: 449.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5564.0000 - fn: 456.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 28/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5572.0000 - fn: 448.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 29/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5570.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1313 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5505.0000 - fn: 445.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1303 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 31/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5500.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1291 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5571.0000 - fn: 449.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1307 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5570.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 34/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1293 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5570.0000 - fn: 450.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1293 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1329 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5576.0000 - fn: 444.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1334 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/60\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.1315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5631.0000 - fn: 459.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 37/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1308 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5498.0000 - fn: 452.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1303 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 38/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1351 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5571.0000 - fn: 449.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1352 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 39/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1305 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5576.0000 - fn: 444.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 40/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1333 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1333 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1381 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5567.0000 - fn: 453.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1376 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 42/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1311 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5569.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1310 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 43/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5501.0000 - fn: 449.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 44/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 45/60\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.1402 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5634.0000 - fn: 456.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1400 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 46/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1292 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5573.0000 - fn: 447.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1294 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 47/60\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.1335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5635.0000 - fn: 455.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1338 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 48/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1319 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5510.0000 - fn: 440.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1322 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 49/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 50/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1322 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1322 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 51/60\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.1281 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5637.0000 - fn: 453.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 52/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1305 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1305 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 53/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1359 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5505.0000 - fn: 445.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1359 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 54/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1437 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5573.0000 - fn: 447.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 55/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5569.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1309 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 56/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 57/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1302 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5569.0000 - fn: 451.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 58/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1325 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5505.0000 - fn: 445.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1325 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 59/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1335 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5563.0000 - fn: 457.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 461.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 60/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1315 - tp: 1.0000 - fp: 0.0000e+00 - tn: 5704.0000 - fn: 460.0000 - precision: 1.0000 - recall: 0.0022\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:55:16.964248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "/var/folders/w9/17dx1py559xc12bhjgp9w4_80000gn/T/ipykernel_4137/1992033442.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp+ fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0.5263584752635847\n",
      "error_rate: 6.268342060478261e-05\n",
      "0.9999999999999984\n",
      " =========== iteration ===========>: 9\n",
      "bfore traning:  80.32441200324412\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:55:17.790537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6510 - tp: 4947.0000 - fp: 1211.0000 - tn: 2.0000 - fn: 5.0000 - precision: 0.8033 - recall: 0.9990\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8905490876922642\n",
      "Recall TRAINING:  0.9989903569221497\n",
      "89/89 [==============================] - 3s 24ms/step - loss: 0.6510 - tp: 4947.0000 - fp: 1211.0000 - tn: 2.0000 - fn: 5.0000 - precision: 0.8033 - recall: 0.9990\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:55:20.778864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428178315905339\n",
      "0.47364152473641524\n",
      "error_rate: 0.00016157409582728572\n",
      "1.0000000000000062\n",
      " =========== iteration ===========>: 10\n",
      "bfore traning:  11.338199513381996\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:55:21.554157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6471 - tp: 15.0000 - fp: 86.0000 - tn: 5380.0000 - fn: 684.0000 - precision: 0.1485 - recall: 0.0215\n",
      "Epoch 2/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1699 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1699 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1590 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1527 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1527 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1491 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1491 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/60\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.1475 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5396.0000 - fn: 694.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1472 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1487 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1487 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1501 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1501 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/60\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.1499 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5461.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1498 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1489 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1494 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1494 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/60\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.1519 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5338.0000 - fn: 682.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1518 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/60\n",
      "89/89 [==============================] - ETA: 0s - loss: 0.1502 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1502 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1593 - tp: 7.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 692.0000 - precision: 1.0000 - recall: 0.0100\n",
      "Epoch 16/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1514 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5273.0000 - fn: 677.0000 - precision: 0.0000e+00 - recall: 0.0000e+00**** Waring: precision recall zero avoid exception ****\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1512 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 699.0000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1554 - tp: 10.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 689.0000 - precision: 1.0000 - recall: 0.0143\n",
      "Epoch 18/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1546 - tp: 15.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 684.0000 - precision: 1.0000 - recall: 0.0215\n",
      "Epoch 19/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1603 - tp: 17.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 682.0000 - precision: 1.0000 - recall: 0.0243\n",
      "Epoch 20/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1550 - tp: 16.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 683.0000 - precision: 1.0000 - recall: 0.0229\n",
      "Epoch 21/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1531 - tp: 14.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 685.0000 - precision: 1.0000 - recall: 0.0200\n",
      "Epoch 22/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1533 - tp: 24.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 675.0000 - precision: 1.0000 - recall: 0.0343\n",
      "Epoch 23/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1539 - tp: 31.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 668.0000 - precision: 1.0000 - recall: 0.0443\n",
      "Epoch 24/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1550 - tp: 69.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 630.0000 - precision: 1.0000 - recall: 0.0987\n",
      "Epoch 25/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1563 - tp: 78.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 621.0000 - precision: 1.0000 - recall: 0.1116\n",
      "Epoch 26/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1561 - tp: 80.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 619.0000 - precision: 1.0000 - recall: 0.1144\n",
      "Epoch 27/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1550 - tp: 116.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 583.0000 - precision: 1.0000 - recall: 0.1660\n",
      "Epoch 28/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1529 - tp: 141.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 558.0000 - precision: 1.0000 - recall: 0.2017\n",
      "Epoch 29/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1511 - tp: 152.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 547.0000 - precision: 1.0000 - recall: 0.2175\n",
      "Epoch 30/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1531 - tp: 205.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 494.0000 - precision: 1.0000 - recall: 0.2933\n",
      "Epoch 31/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1512 - tp: 203.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 496.0000 - precision: 1.0000 - recall: 0.2904\n",
      "Epoch 32/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1516 - tp: 262.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 437.0000 - precision: 1.0000 - recall: 0.3748\n",
      "Epoch 33/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1545 - tp: 268.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 431.0000 - precision: 1.0000 - recall: 0.3834\n",
      "Epoch 34/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1600 - tp: 300.0000 - fp: 1.0000 - tn: 5465.0000 - fn: 399.0000 - precision: 0.9967 - recall: 0.4292\n",
      "Epoch 35/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1517 - tp: 321.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 378.0000 - precision: 1.0000 - recall: 0.4592\n",
      "Epoch 36/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1476 - tp: 335.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 364.0000 - precision: 1.0000 - recall: 0.4793\n",
      "Epoch 37/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1506 - tp: 368.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 331.0000 - precision: 1.0000 - recall: 0.5265\n",
      "Epoch 38/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1479 - tp: 357.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 342.0000 - precision: 1.0000 - recall: 0.5107\n",
      "Epoch 39/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1473 - tp: 372.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 327.0000 - precision: 1.0000 - recall: 0.5322\n",
      "Epoch 40/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1549 - tp: 398.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 301.0000 - precision: 1.0000 - recall: 0.5694\n",
      "Epoch 41/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1467 - tp: 406.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 293.0000 - precision: 1.0000 - recall: 0.5808\n",
      "Epoch 42/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1429 - tp: 425.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 274.0000 - precision: 1.0000 - recall: 0.6080\n",
      "Epoch 43/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1415 - tp: 436.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 263.0000 - precision: 1.0000 - recall: 0.6237\n",
      "Epoch 44/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1605 - tp: 459.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 240.0000 - precision: 1.0000 - recall: 0.6567\n",
      "Epoch 45/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1541 - tp: 459.0000 - fp: 3.0000 - tn: 5463.0000 - fn: 240.0000 - precision: 0.9935 - recall: 0.6567\n",
      "Epoch 46/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1467 - tp: 444.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 255.0000 - precision: 1.0000 - recall: 0.6352\n",
      "Epoch 47/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1521 - tp: 459.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 240.0000 - precision: 1.0000 - recall: 0.6567\n",
      "Epoch 48/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1359 - tp: 467.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 232.0000 - precision: 1.0000 - recall: 0.6681\n",
      "Epoch 49/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1382 - tp: 478.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 221.0000 - precision: 1.0000 - recall: 0.6838\n",
      "Epoch 50/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1409 - tp: 452.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 247.0000 - precision: 1.0000 - recall: 0.6466\n",
      "Epoch 51/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1378 - tp: 465.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 234.0000 - precision: 1.0000 - recall: 0.6652\n",
      "Epoch 52/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1476 - tp: 475.0000 - fp: 0.0000e+00 - tn: 5466.0000 - fn: 224.0000 - precision: 1.0000 - recall: 0.6795\n",
      "Epoch 53/60\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1505 - tp: 488.0000 - fp: 2.0000 - tn: 5464.0000 - fn: 211.0000 - precision: 0.9959 - recall: 0.6981\n",
      "Epoch 54/60\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.1593 - tp: 498.0000 - fp: 3.0000 - tn: 5268.0000 - fn: 181.0000 - precision: 0.9940 - recall: 0.7334\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.8453947363194454\n",
      "Recall TRAINING:  0.735336184501648\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1583 - tp: 514.0000 - fp: 3.0000 - tn: 5463.0000 - fn: 185.0000 - precision: 0.9942 - recall: 0.7353\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:56:21.729074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6636155606407322\n",
      "0.7615571776155717\n",
      "error_rate: 3.079801018572875e-05\n",
      "1.0000000000000129\n",
      " =========== iteration ===========>: 11\n",
      "bfore traning:  74.27412814274128\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:56:22.548103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - ETA: 0s - loss: 0.6952 - tp: 4230.0000 - fp: 525.0000 - tn: 1061.0000 - fn: 349.0000 - precision: 0.8896 - recall: 0.9238\n",
      "\n",
      "******* Stoping on Defined Thresold *******\n",
      "F1 TRAINING:  0.9063638516560926\n",
      "Recall TRAINING:  0.9237825274467468\n",
      "89/89 [==============================] - 3s 25ms/step - loss: 0.6952 - tp: 4230.0000 - fp: 525.0000 - tn: 1061.0000 - fn: 349.0000 - precision: 0.8896 - recall: 0.9238\n",
      "\n",
      "\n",
      "\n",
      "****** Early Stopping *******\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "0.42876344086021506\n",
      "0.31062449310624496\n",
      "error_rate: 0.00011054060001555545\n",
      "1.0000000000000098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:56:25.689336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# plt.plot(initial_weight)\n",
    "boosting(initial_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.7995690750306808,\n 1.7655383894871992,\n 2.0715505116517234,\n 1.6780164042196706,\n 2.1472225274279397,\n 1.6562598615973685,\n 2.121911227139861,\n 1.6644412937992812,\n 1.9354701768144975,\n 1.7460770271349089,\n 2.07760593518934,\n 1.8220034273647372]"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "\n",
    "def repeat(test_split, test_result, start, end):\n",
    "    mx = 0\n",
    "    size = 0\n",
    "    data = []\n",
    "    f1=[]\n",
    "    for i in range(start,end):\n",
    "        data = some_pred(test_split, i)\n",
    "        tn, fp, fn, tp = confusion_matrix(test_result, data).ravel()\n",
    "        precision = tp / (tp+ fp)\n",
    "        recall = tp / (tp+ fn)\n",
    "        score = (2 * precision * recall) / (precision + recall)\n",
    "        print(score)\n",
    "        f1.append(score)\n",
    "        if mx < score:\n",
    "            mx = score\n",
    "            size = i\n",
    "        print(i)\n",
    "    print(mx,size)\n",
    "    return data, f1\n",
    "\n",
    "# a = ensemble[0].predict(test_split)\n",
    "\n",
    "def some_pred(test_split, esize):\n",
    "#     data = []\n",
    "    k = []\n",
    "#     for j in range(len(test_split)):\n",
    "#         pa=0\n",
    "#         na =0\n",
    "    for i in range(esize):\n",
    "        print('*********:', i)\n",
    "        k.append(ensemble[i].predict([test_split]))\n",
    "        # if pa >=na:\n",
    "        #     data.append(1)\n",
    "        # else:\n",
    "        #     data.append(0)\n",
    "    # f1.append(f1_score(test_result, data, average=\"macro\"))\n",
    "    # acc.append(accuracy_score(test_result, data))\n",
    "    return k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "\n",
    "def majority(data):\n",
    "    ans =[]\n",
    "    for i in range(len(data[0])):\n",
    "        ap = 0\n",
    "        an = 0\n",
    "        for e in range(len(data)):\n",
    "            if data[e][i] >= .5:\n",
    "                ap += alphas[e]\n",
    "            else:\n",
    "                an += alphas[e]\n",
    "        if ap >= an:\n",
    "            ans.append(1)\n",
    "        else:\n",
    "            ans.append(0)\n",
    "    return ans\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "def getf1(true, predicted):\n",
    "    tn, fp, fn, tp = confusion_matrix(true, predicted).ravel()\n",
    "    precision = tp / (tp+ fp)\n",
    "    recall = tp / (tp+ fn)\n",
    "    score = (2 * precision * recall) / (precision + recall)\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********: 0\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 7\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 7\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 9\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 9\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 10\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 2\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 3\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 5\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 8\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 9\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "*********: 10\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "*********: 11\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "f1_test = []\n",
    "for i in range(1,13):\n",
    "    data = some_pred(test_split, i)\n",
    "    ans = majority(data)\n",
    "    f1_test.append(getf1(test_result, ans))\n",
    "    # ConfusionMatrixDisplay.from_predictions(test_result,ans,cmap='Greens')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********: 0\n",
      "3/3 [==============================] - 0s 8ms/step\n",
      "*********: 1\n",
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2ddc3ecd0>"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = some_pred(test_split, 2)\n",
    "ans = majority(data)\n",
    "ConfusionMatrixDisplay.from_predictions(test_result,ans,cmap='Greens')\n",
    "# plt.plot(f1_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********: 0\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 9\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "*********: 9\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 10\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "*********: 0\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 2\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 3\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 4\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 5\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 6\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 7\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 8\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 9\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 10\n",
      "39/39 [==============================] - 0s 2ms/step\n",
      "*********: 11\n",
      "39/39 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "f1_train = []\n",
    "for i in range(1,13):\n",
    "    data = some_pred(training_split, i)\n",
    "    ans = majority(data)\n",
    "    f1_train.append(getf1(train_result, ans))\n",
    "    # ConfusionMatrixDisplay.from_predictions(test_result,ans,cmap='Greens')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2ddc28610>]"
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5BElEQVR4nO3de3RU9b338c9MLjMJJBNIICEhEK4CAokmkkbaqsdoqh5arUW8wpNWztJiD5qnp5Uq0JtGbeVglSOVI8fWS0Wtt1bE0njpwzEVTIyCchG5JESSECAzkJDbzDx/DBkSSUImTLLn8n6ttVc2O3vPfJOlzIf9+/2+2+R2u90CAAAwiNnoAgAAQHgjjAAAAEMRRgAAgKEIIwAAwFCEEQAAYCjCCAAAMBRhBAAAGIowAgAADBVpdAF94XK59OWXXyouLk4mk8nocgAAQB+43W4dO3ZMqampMpt7vv8RFGHkyy+/VHp6utFlAACAfqiqqtLo0aN7/H5QhJG4uDhJnh8mPj7e4GoAAEBfOBwOpaenez/HexIUYaRjaCY+Pp4wAgBAkDnTFAsmsAIAAEMRRgAAgKEIIwAAwFCEEQAAYCjCCAAAMBRhBAAAGIowAgAADEUYAQAAhvI5jPzjH//QnDlzlJqaKpPJpFdfffWM17z77rs6//zzZbFYNHHiRD311FP9KBUAAIQin8NIY2OjMjMztWrVqj6dv3fvXl111VW65JJLVFFRoTvvvFO33nqr3nrrLZ+LBQAAocfndvBXXHGFrrjiij6fv3r1ao0bN04PP/ywJGnq1KnatGmT/vM//1MFBQW+vj0AAAgxAz5npLS0VPn5+V2OFRQUqLS0tMdrWlpa5HA4umwAACA0DXgYqampUXJycpdjycnJcjgcOnHiRLfXFBcXy2azebf09PSBLhMAgLBTf7xFz31QqX/744dqbXcZVkdAPrV3yZIlKioq8v654xHEAADg7NQ6mvXWpzVav/WgNu89Ipfbc/z9L+p18TkjDalpwMNISkqKamtruxyrra1VfHy8YmJiur3GYrHIYrEMdGkAAISFLxtO6M1tNXpz60GVVR6V233qezNH2/St6Sk6JyXOsPoGPIzk5eVp/fr1XY5t3LhReXl5A/3WAACEraojTXpz20Gt31qjiqqGLt87b0yCrpw+St+anqL04bHGFNiJz2Hk+PHj2r17t/fPe/fuVUVFhYYPH64xY8ZoyZIlqq6u1h//+EdJ0m233abHHntMP/nJT/T9739fb7/9tl544QW98cYb/vspAACA9hw67rkDsu2gtlWfWvxhMkkXjB2uK2ak6FvTUzTK1v3IhFF8DiMffvihLrnkEu+fO+Z2LFiwQE899ZQOHjyoyspK7/fHjRunN954Q3fddZceeeQRjR49Wv/93//Nsl4AAPzg89pjWr/VE0B21BzzHjebpK+NT9QV01NUcG6KRsZbDayydya3u/PIUWByOByy2Wyy2+2Kj483uhwAAAzjdru1/eAxvbntoN7cVqPddce934s0m5Q3IVFXzhily6clK3GosfMv+/r5HZCraQAAwClut1tbq+3eSaj7Djd5vxcVYdI3Jo3QFdNTdNm0ZCXERhtYaf8QRgAEpDanS8ea22U/0SbHiTY5mttO7rd32m+T4yvnOE606USr0+jyMUisUREakxircYlDNDZxiDKSYj1fE2OD8kO5M5fLrY+qGrTh5CTU6oZTvbmiI826ePIIXTEjRZdOTVa8NcrASs8eYQTAgHC53Dre2i57U0dIOBkamk+FCEcvQaOJQIE+aGx16nBjqz6qbDjtewmxUd5g0vE1I2mIMhKHaFhslEwm0+AXfAZOl1tl+49q/daD2rCtRjWOZu/3YqIi9C9TRupb01N0yZSRGmoJnY/w0PlJgCC3/3CjtlU75FZgT+Nqc7o8oeFEW6dw0SloNLfJ3tSmYy3t8seMtKGWSMVbIxUfE6V4a5Tna0yk4q1RssWc/LM1stN+lGKjIxSAnzMYAMea27X/cJP2HW7U/sON2ne4SfsPN6rW0aKGpjY1NDXo468sa5WkOGukMhKHaGxirMYlDekSWpKGRg9qUGl3urR57xGt33ZQb31aq0PHWrzfGxIdoUunJuvKGSm6aPJIxURHDFpdg4kwAhiosaVdb2w9qJc+PKDN+44YXc6AsESauw0Mtm5DheeY7eR+nDVSkRED/tQKBLnpabbTjjW1ekJK54Cyt75R+w836aC9Wcea27W12q6t1fbTrh1qidTYxFhvWOkcWkbEWfwSVNqcLr3/xWFtOBlAjjS2er8XZ43UZdOSdeX0Ufr6pCRZo0IzgHTGahpgkLndbm3Zd1QvflilN7Ye9A5HmExS5ugEWaMC+8M30mzuEiTiO92diI+J8gaJju+Hw1+kCC7NbU5VHmnSvvpG7esUVvbVN+lL+4le7+jFREWcCihJXeeqJMdZZTb3HFRa2p3a9Hm93txWo42f1cp+os37vYTYKBVMS9G3ZqRo9oQkRUcG9t8DfcVqGiDAfNlwQi+XH9BLZQe6zITPSIzV3Jx0fff8tIBrRASEImtUhCYnx2ly8untz1vanao6csIbVE4NATXpwNEmnWhzakfNsS79PDpYIs3eoJKRdOquyrHmdm3YdlAl2+t0rKXde37S0Ghdfm6Krpw+SrnjhysqjO8CEkaAAdTc5tTfPqvVix9WadPueu+/uIZER+iqmaM0NyddOWOHBeREOiAcWSIjNHHkUE0cOfS077W2u3TgaFOXgOIZ+mlU1dETaml3aVftce2qPd7NK3uMjLPoiukpumLGKF2QMVwRvdxJCSeEEcDP3G63Pjlg14tlVXq94ks5mk/9Syh33HDNzUnXFdNTNCSEZsID4SA60qzxI4Zq/IjTg0qb06UvG05o3+Gm0+6quFxuXTo1WVdMT9H5Y4b1OpQTrvjbEPCTQ8da9OpH1XqxrKrLv4zSEmJ07flpujZ7tMYmDjGwQgADJSrCrLEn549cNHmE0eUEHcIIcBbanC69vaNOL354QO/urFO7yzMOY4k061vTUzQ3O10XTkjkX0IA0AvCCNAPO2ocevHDA3r1o2od7rQkLzM9QdfljNa/zkyVLSa4OyICwGAhjAB9ZG9q0+sfV+vFsgP65MCp3gRJQy367vlpmps9WpO6mZ0PAOgdYQTohdPl1qbd9Xrxwyr97bNatba7JHmejHnp1JGam52ui84ZEdZL8gDgbBFGgG7srW/US2VVerm8Wgftp54NMSUlTnNz0nV1Vqrhj+YGgFBBGAFOOt7SrvWfHNSLZVXasu+o93hCbJS+k5mquTnpOjc1np4gAOBnhBGENbfbrQ/2HtGLHx7Qm9tOtWY3m6RvTh6hudnpyp82UpZIWpoDwEAhjCAsVTec0J/LPK3ZK4+cas0+PmmIvpczWt89b7RSbFYDKwSA8EEYQdhobnPqrU9r9OKHB/S/X3RtzT4nM1Vzc0br/DG0ZgeAwUYYwVn7c9kB/fGf++VyBfYDoPcdbtSxTq3Z88Yn6nvZo3XFjBTFRvO/AgAYhb+BcVbe3VmnH7/0ca+P3A4kaQkxujZ7tOZmj1b68FijywEAiDCCs1B1pEl3rquQ2y1997w0zclKNbqkXtliopQ1OoHW7AAQYAgj6JfmNqd++Gy5GpralDnapuJrZ7DiBADQL7SNRL/8/PVPtbXarmGxUfqvm7MJIgCAfiOMwGcvbKnS81uqZDJJj1x/ntISYowuCQAQxAgj8Mm2arvufW2bJKkof7K+OXmEwRUBAIIdYQR91tDUqtueKVNru0uXThmpRZdMNLokAEAIIIygT1wut+5aV6EDR09ozPBYrZiXxaoUAIBfEEbQJ4++vVvv7DwkS6RZj998vmwxUUaXBAAIEYQRnNG7O+u0smSXJOm+a2bo3FSbwRUBAEIJYQS9qjrSpMXPexqb3Zg7Rt/LHm10SQCAEEMYQY86GpvZT3gamy2fM83okgAAIYgwgh7R2AwAMBj6FUZWrVqljIwMWa1W5ebmavPmzT2e29bWpl/+8peaMGGCrFarMjMztWHDhn4XjMFBYzMAwGDxOYysW7dORUVFWr58ucrLy5WZmamCggLV1dV1e/69996r3//+93r00Uf12Wef6bbbbtM111yjjz766KyLx8Do3Njs/15GYzMAwMAyud2+Pfw9NzdXF1xwgR577DFJksvlUnp6un70ox/p7rvvPu381NRU3XPPPVq0aJH32LXXXquYmBg988wzfXpPh8Mhm80mu92u+Ph4X8qFjxqaWvWvj27SgaMnlD91pJ64JYd+IgCAfunr57dPd0ZaW1tVVlam/Pz8Uy9gNis/P1+lpaXdXtPS0iKr1drlWExMjDZt2tTj+7S0tMjhcHTZMPBcLrfu7NTY7OHraGwGABh4PoWR+vp6OZ1OJScndzmenJysmpqabq8pKCjQihUr9Pnnn8vlcmnjxo16+eWXdfDgwR7fp7i4WDabzbulp6f7Uib66Xdvf653aWwGABhkA76a5pFHHtGkSZM0ZcoURUdH64477lBhYaHM5p7fesmSJbLb7d6tqqpqoMsMe+/urNMjJZ9LorEZAGBw+RRGkpKSFBERodra2i7Ha2trlZKS0u01I0aM0KuvvqrGxkbt379fO3bs0NChQzV+/Pge38disSg+Pr7LhoFDYzMAgJF8CiPR0dHKzs5WSUmJ95jL5VJJSYny8vJ6vdZqtSotLU3t7e3685//rO985zv9qxh+RWMzAIDRIn29oKioSAsWLFBOTo5mzZqllStXqrGxUYWFhZKk+fPnKy0tTcXFxZKkDz74QNXV1crKylJ1dbV+/vOfy+Vy6Sc/+Yl/fxL0C43NAABG8zmMzJs3T4cOHdKyZctUU1OjrKwsbdiwwTuptbKysst8kObmZt17773as2ePhg4dqiuvvFJPP/20EhIS/PZDoH86Nzb73Q00NgMAGMPnPiNGoM+I/22rtuu7j7+v1naXfnz5ZN3xL5OMLgkAEGIGpM8IQkNDU6tue6ZMre0u5U8dqR9ePNHokgAAYYwwEmZobAYACDSEkTBDYzMAQKAhjIQRGpsBAAIRYSRM0NgMABCoCCNhgMZmAIBARhgJAzQ2AwAEMsJIiFu3pZLGZgCAgEYYCWFbD9i19LVPJUn/97LJ+sakEQZXBADA6QgjIaqhqVW3P0tjMwBA4COMhCAamwEAgglhJATR2AwAEEwIIyHmHRqbAQCCDGEkhFQdadKdJxub3URjMwBAkCCMhIjmNqduf7bM09gsPUHLaGwGAAgShJEQsfy1T7Wt2uFpbHbT+TQ2AwAEDcJICFi3pVLrPqSxGQAgOBFGghyNzQAAwY4wEsRobAYACAWEkSDlcrm1+HkamwEAgh9hJEg9UvK53tvlaWy2+uZsGpsBAIIWYSQIvbOzTr9729PY7P5rZmhaarzBFQEA0H+EkSDz1cZm19LYDAAQ5CKNLsBQf/i2VF1udBV95pZbiW1ObXJJETFSzPYIaTvzRACEsWFjpf/zhhSTYHQlOAvhHUbaTkitx4yuos9MkmI7dtySWg0tBwCMV7tN2v+/0pSrjK4EZyG8w8jcpyRni9FV9MlfPzmoh97aKZOk386dqQsyhhtdEgAY629LpR1/lep3SSKMBLPwDiO2NKMr6JOtB+wq+vtOtbqT9ePLJ+uC8ycZXRIAGG9U5skw8rnRleAshXUYOXy8Re0ut9Fl9Kqp1anbnqGxGQCcJunkP8zqdxlbB85aWIeRhX/8UOWVDUaX0SdjE2lsBgBdJE32fK3fJbndkom/H4NVWIeRCLNJEUHw4T5meKxW3Xg+jc0AoLPhEySZpGa71HhIGjrS6IrQT2EdRl687UKjSwAA9FeU1bO09+g+z90RwkjQoukZACB4dR6qQdDqVxhZtWqVMjIyZLValZubq82bN/d6/sqVK3XOOecoJiZG6enpuuuuu9Tc3NyvggEA8PKGEVbUBDOfw8i6detUVFSk5cuXq7y8XJmZmSooKFBdXV235z/33HO6++67tXz5cm3fvl1PPvmk1q1bp5/97GdnXTwAIMyxoiYk+BxGVqxYoYULF6qwsFDTpk3T6tWrFRsbq7Vr13Z7/vvvv6/Zs2frxhtvVEZGhi6//HLdcMMNZ7ybAgDAGTFMExJ8CiOtra0qKytTfn7+qRcwm5Wfn6/S0tJur7nwwgtVVlbmDR979uzR+vXrdeWVV/b4Pi0tLXI4HF02AABO0xFGGqqk1iZja0G/+bSapr6+Xk6nU8nJyV2OJycna8eOHd1ec+ONN6q+vl5f//rX5Xa71d7erttuu63XYZri4mL94he/8KU0AEA4ik2UYoZJJ45KR76QUmYYXRH6YcBX07z77ru6//779V//9V8qLy/Xyy+/rDfeeEO/+tWverxmyZIlstvt3q2qqmqgywQABCOTiaGaEODTnZGkpCRFRESotra2y/Ha2lqlpKR0e83SpUt1yy236NZbb5UkzZgxQ42Njfq3f/s33XPPPTKbT89DFotFFovFl9IAAOEqaZJU9QEraoKYT3dGoqOjlZ2drZKSEu8xl8ulkpIS5eXldXtNU1PTaYEjIiJCkuR2B/ZzYQAAQYA7I0HP5w6sRUVFWrBggXJycjRr1iytXLlSjY2NKiwslCTNnz9faWlpKi4uliTNmTNHK1as0Hnnnafc3Fzt3r1bS5cu1Zw5c7yhBACAfiOMBD2fw8i8efN06NAhLVu2TDU1NcrKytKGDRu8k1orKyu73Am59957ZTKZdO+996q6ulojRozQnDlzdN999/nvpwAAhC9vGNktuVxSN8P/CGwmdxCMlTgcDtlsNtntdsXHxxtdDgAgkDjbpftSJFebdOdWKWGM0RXhpL5+fhMfAQDBLSJSSpzg2WeoJigRRgAAwc/bFp4VNcGIMAIACH5MYg1qhBEAQPDj6b1BjTACAAh+PL03qBFGAADBL/FkGDleK51oMLQU+I4wAgAIftZ4KW6UZ//wbmNrgc8IIwCA0MBQTdAijAAAQgMraoIWYQQAEBpYURO0CCMAgNDAME3QIowAAEJDx52RI3skZ5uxtcAnhBEAQGiIS5WihkiudunoPqOrgQ8IIwCA0GA2S0kTPfsM1QQVwggAIHSwoiYoEUYAAKGDFTVBiTACAAgdrKgJSoQRAEDo6DxM43YbWwv6jDACAAgdwydIMknNdqnxkNHVoI8IIwCA0BFllYaN9ewzVBM0CCMAgNDCipqgQxgBAIQWVtQEHcIIACC0sKIm6BBGAAChhWGaoEMYAQCElo4w0lAltTYZWwv6hDACAAgtsYlSzDBJbunIF0ZXgz4gjAAAQovJxFBNkCGMAABCj3cSKytqggFhBAAQergzElQIIwCA0EMYCSqEEQBA6PGGkd2Sy2VsLTgjwggAIPQkjJXMUVL7CclxwOhqcAb9CiOrVq1SRkaGrFarcnNztXnz5h7Pvfjii2UymU7brrrqqn4XDQBAryIipcQJnn2GagKez2Fk3bp1Kioq0vLly1VeXq7MzEwVFBSorq6u2/NffvllHTx40Ltt27ZNERERmjt37lkXDwBAj1hREzR8DiMrVqzQwoULVVhYqGnTpmn16tWKjY3V2rVruz1/+PDhSklJ8W4bN25UbGwsYQQAMLCYxBo0fAojra2tKisrU35+/qkXMJuVn5+v0tLSPr3Gk08+qeuvv15Dhgzp8ZyWlhY5HI4uGwAAPuHpvUHDpzBSX18vp9Op5OTkLseTk5NVU1Nzxus3b96sbdu26dZbb+31vOLiYtlsNu+Wnp7uS5kAAPD03iAyqKtpnnzySc2YMUOzZs3q9bwlS5bIbrd7t6qqqkGqEAAQMhJPhpHjtdKJBkNLQe98CiNJSUmKiIhQbW1tl+O1tbVKSUnp9drGxkY9//zz+sEPfnDG97FYLIqPj++yAQDgE2u8FDfKs394t7G1oFc+hZHo6GhlZ2erpKTEe8zlcqmkpER5eXm9Xvviiy+qpaVFN998c/8qBQDAVwzVBAWfh2mKioq0Zs0a/eEPf9D27dt1++23q7GxUYWFhZKk+fPna8mSJadd9+STT+rqq69WYmLi2VcNAEBfsKImKET6esG8efN06NAhLVu2TDU1NcrKytKGDRu8k1orKytlNnfNODt37tSmTZv0t7/9zT9VAwDQF6yoCQomt9vtNrqIM3E4HLLZbLLb7cwfAQD03RdvS09f4wkld2wxupqw09fPb55NAwAIXR13Ro7skZxtxtaCHhFGAAChKy5Vihoiudqlo/uMrgY9IIwAAEKX2SwlTfTsM4k1YBFGAAChjRU1AY8wAgAIbayoCXiEEQBAaKPxWcAjjAAAQlvnYZrA72YRlggjAIDQNnyCJJPUbJcaDxldDbpBGAEAhLYoqzRsrGefoZqARBgBAIQ+VtQENMIIACD0saImoBFGAAChjxU1AY0wAgAIfQzTBDTCCAAg9HWEkYYqqbXJ2FpwGsIIACD0xSZKMcMkuaUjXxhdDb6CMAIACH0mE0M1AYwwAgAID95JrKyoCTSEEQBAeODOSMAijAAAwgNhJGARRgAA4cEbRnZLLpextaALwggAIDwkjJXMUVL7CclxwOhq0AlhBAAQHiIipcQJnn2GagIKYQQAED5YUROQCCMAgPDBJNaARBgBAIQPnt4bkAgjAIDwwdN7AxJhBAAQPhJPhpHjtdKJBkNLwSmEEQBA+LDGS3GjPPuHdxtbC7wIIwCA8MJQTcAhjAAAwgsragIOYQQAEF5YURNwCCMAgPDCME3AIYwAAMJLx52RI3slZ5uxtUBSP8PIqlWrlJGRIavVqtzcXG3evLnX8xsaGrRo0SKNGjVKFotFkydP1vr16/tVMAAAZyUuVYoaIrnapKP7ja4G6kcYWbdunYqKirR8+XKVl5crMzNTBQUFqqur6/b81tZWXXbZZdq3b59eeukl7dy5U2vWrFFaWtpZFw8AgM/MZilpomefoZqA4HMYWbFihRYuXKjCwkJNmzZNq1evVmxsrNauXdvt+WvXrtWRI0f06quvavbs2crIyNBFF12kzMzMsy4eAIB+YUVNQPEpjLS2tqqsrEz5+fmnXsBsVn5+vkpLS7u95vXXX1deXp4WLVqk5ORkTZ8+Xffff7+cTmeP79PS0iKHw9FlAwDAb1hRE1B8CiP19fVyOp1KTk7ucjw5OVk1NTXdXrNnzx699NJLcjqdWr9+vZYuXaqHH35Yv/71r3t8n+LiYtlsNu+Wnp7uS5kAAPSOFTUBZcBX07hcLo0cOVJPPPGEsrOzNW/ePN1zzz1avXp1j9csWbJEdrvdu1VVVQ10mQCAcNJ5mMbtNrYWKNKXk5OSkhQREaHa2toux2tra5WSktLtNaNGjVJUVJQiIiK8x6ZOnaqamhq1trYqOjr6tGssFossFosvpQEA0HfDJ0gySc0NUmO9NHSE0RWFNZ/ujERHRys7O1slJSXeYy6XSyUlJcrLy+v2mtmzZ2v37t1yuVzeY7t27dKoUaO6DSIAAAy4KKs0bKxnn6Eaw/k8TFNUVKQ1a9boD3/4g7Zv367bb79djY2NKiwslCTNnz9fS5Ys8Z5/++2368iRI1q8eLF27dqlN954Q/fff78WLVrkv58CAABfsaImYPg0TCNJ8+bN06FDh7Rs2TLV1NQoKytLGzZs8E5qrayslNl8KuOkp6frrbfe0l133aWZM2cqLS1Nixcv1k9/+lP//RQAAPgqabL0+d9YURMATG534M/ccTgcstlsstvtio+PN7ocAEAoKHtK+stiaeJl0s0vGV1NSOrr5zfPpgEAhCeGaQIGYQQAEJ46wkhDpdR2wthawhxhBAAQnmITpZhhktzS4S+MriasEUYAAOHJZGKoJkAQRgAA4cvbFp4VNUYijAAAwhd3RgICYQQAEL4IIwGBMAIACF8dYeTwbqnTY0swuAgjAIDwlTBWMkdJbU2So9roasIWYQQAEL4iIqXECZ59hmoMQxgBAIQ3VtQYjjACAAhvTGI1HGEEABDeCCOGI4wAAMIbwzSGI4wAAMJb4skwcrxGarYbW0uYIowAAMKbNV6KG+XZr99tbC1hijACAIB3qIZ5I0YgjAAAwCRWQxFGAAAgjBiKMAIAACtqDEUYAQCg487IkT2Ss83YWsIQYQQAgLhUKWqI5GqTju43upqwQxgBAMBslpImevaZNzLoCCMAAEhMYjUQYQQAAKlTGGES62AjjAAAINH4zECEEQAApK7DNG63sbWEGcIIAACSNHyCJJPU3CA11htdTVghjAAAIElRVmnYWM8+QzWDijACAEAHVtQYgjACAEAHVtQYgjACAEAHVtQYol9hZNWqVcrIyJDValVubq42b97c47lPPfWUTCZTl81qtfa7YAAABgzDNIbwOYysW7dORUVFWr58ucrLy5WZmamCggLV1dX1eE18fLwOHjzo3fbvp+8/ACAAdYSRhkqp7YSxtYQRn8PIihUrtHDhQhUWFmratGlavXq1YmNjtXbt2h6vMZlMSklJ8W7JyclnVTQAAAMiNlGyJkhyS4e/MLqasOFTGGltbVVZWZny8/NPvYDZrPz8fJWWlvZ43fHjxzV27Filp6frO9/5jj799NNe36elpUUOh6PLBgDAgDOZGKoxgE9hpL6+Xk6n87Q7G8nJyaqpqen2mnPOOUdr167Va6+9pmeeeUYul0sXXnihDhw40OP7FBcXy2azebf09HRfygQAoP9YUTPoBnw1TV5enubPn6+srCxddNFFevnllzVixAj9/ve/7/GaJUuWyG63e7eqqqqBLhMAAA9W1Ay6SF9OTkpKUkREhGpra7scr62tVUpKSp9eIyoqSuedd552797d4zkWi0UWi8WX0gAA8A+GaQadT3dGoqOjlZ2drZKSEu8xl8ulkpIS5eXl9ek1nE6ntm7dqlGjRvlWKQAAg6EjjBzeLblcxtYSJny6MyJJRUVFWrBggXJycjRr1iytXLlSjY2NKiwslCTNnz9faWlpKi4uliT98pe/1Ne+9jVNnDhRDQ0N+s1vfqP9+/fr1ltv9e9PAgCAPwwbK5mjpLYmyVEtJTBvcaD5HEbmzZunQ4cOadmyZaqpqVFWVpY2bNjgndRaWVkps/nUDZejR49q4cKFqqmp0bBhw5Sdna33339f06ZN899PAQCAv0REScPHS/U7PUM1hJEBZ3K73W6jizgTh8Mhm80mu92u+Ph4o8sBAIS652+SdvxV+taD0tduM7qaoNXXz2+eTQMAwFcxiXVQEUYAAPgqwsig8nnOCAAAIS+cGp/97V6p5biUt+hUj5VBxp0RAAC+Kmmi5+vxGqnZbmwtA6nthFT2B6nsf6Rj3XdSHwyEEQAAvspqk4aebOZZ33OTzqC34w2pxSHZxkhjZxtWBmEEAIDuhENb+IpnPV+zbpDMxkUCwggAAN0J9Umsji+lPe969jOvN7QUwggAAN0J9TDyyTrJ7ZLG5HmavBmIMAIAQHe8wzQhuKLG7ZYqnvPsZ91obC0ijAAA0L2OOyNH9kjONmNr8bfqcs8dn8gYadrVRldDGAEAoFvxaVJUrORqk47uN7oa//r45F2Rqf8qWY1/zAphBACA7pjNUuLJfiOhNG+kvUXa+pJnPwCGaCTCCAAAPQvFSaw735SaG6S4VGncRUZXI4kwAgBAz0KxLfzHf/J8zZwnmSOMreUkwggAAD0JtcZnx+ukzzd69jMDY4hGIowAANCzzsM0brextfjDJy9IbqeUliONmGx0NV6EEQAAepI4QZLJM8eisd7oas5Ol94iNxhby1cQRgAA6ElUjJQwxrMf7EM1NZ9IdZ9KEdHS9GuNrqYLwggAAL0JlRU1FScnrp5zpRQzzNhavoIwAgBAb0JhRU17q7T1Bc9+gPQW6YwwAgBAb0JhRc3ujVLTYWnISGnCpUZXcxrCCAAAvQmFYZqOiaszr5MiIo2tpRuEEQAAetMRRhoqpbYTxtbSH42HpV1vefYDcIhGIowAANC7IUmSNUGSWzr8hdHV+G7bS56H/Y3KlJLPNbqabhFGAADojckU3EM1HUM0AdRx9asIIwAAnEmwrqip/Uw6WCGZI6UZ3zO6mh4RRgAAOJNgXVHz8cm7IpO/5RluClCEEQAAziQYh2mc7Z5n0UhSZmC1f/8qwggAAGfSEUYO75ZcLmNr6as970jHa6WY4dKky42upleEEQAAzmTYWMkcJbU1SY5qo6vpm4pnPV9nXidFRhtbyxkQRgAAOJOIKGn4eM9+MAzVnDgq7Vjv2Q/wIRqJMAIAQN94J7EGwYqaT1+RnC3SyGme/iIBrl9hZNWqVcrIyJDValVubq42b97cp+uef/55mUwmXX311f15WwAAjBNMk1g7eotk3ejpkxLgfA4j69atU1FRkZYvX67y8nJlZmaqoKBAdXV1vV63b98+/fjHP9Y3vvGNfhcLAIBhgiWM1H8uHdgimSKkGdcZXU2f+BxGVqxYoYULF6qwsFDTpk3T6tWrFRsbq7Vr1/Z4jdPp1E033aRf/OIXGj9+/FkVDACAIYKl8dnHf/J8nXipFJdsbC195FMYaW1tVVlZmfLz80+9gNms/Px8lZaW9njdL3/5S40cOVI/+MEP+vQ+LS0tcjgcXTYAAAyVNNHz9XiN1Gw3tpaeuJzSx8979gP0oXjd8SmM1NfXy+l0Kjm5a9JKTk5WTU1Nt9ds2rRJTz75pNasWdPn9ykuLpbNZvNu6enpvpQJAID/WW3S0BTPfv1uY2vpyd5/eJYeW23S5CuMrqbPBnQ1zbFjx3TLLbdozZo1SkrqexvaJUuWyG63e7eqqqoBrBIAgD4K9LbwHUM006+VoqzG1uKDSF9OTkpKUkREhGpra7scr62tVUpKymnnf/HFF9q3b5/mzJnjPeY62bkuMjJSO3fu1IQJE067zmKxyGKx+FIaAAADL2mytO//BWYYaXZIn73u2c+6ydhafOTTnZHo6GhlZ2erpKTEe8zlcqmkpER5eXmnnT9lyhRt3bpVFRUV3u3b3/62LrnkElVUVDD8AgAILoG8ouaz16T2E1LiJCkt2+hqfOLTnRFJKioq0oIFC5STk6NZs2Zp5cqVamxsVGFhoSRp/vz5SktLU3FxsaxWq6ZPn97l+oSEBEk67TgAAAEvkBufdQzRZN0QFL1FOvM5jMybN0+HDh3SsmXLVFNTo6ysLG3YsME7qbWyslJmM41dAQAhqOPOyJE9krPN0yY+EBzZK+3/X0kmaeb1RlfjM5Pb7XYbXcSZOBwO2Ww22e12xcfHG10OACBcuVxScZrngXl3lJ1a7mu0d4ql9x6Qxl8izX/V6Gq8+vr5zS0MAAD6ymyWEk8GkECZN+JydRqiCZ7eIp0RRgAA8EWgTWKtfF9q2C9Fx0lT/tXoavqFMAIAgC8CrS18xcm7IudeLUXHGlpKfxFGAADwRSA1PmttlD571bMfpEM0EmEEAADfdB6mMXoNyPa/SK3HpWEZ0pjT+30FC8IIAAC+SJwgySQ1N0iN9cbWUvGc52vmjUHXW6QzwggAAL6IipESxnj2jRyqaajyPBhPkjKDr7dIZ4QRAAB8FQgraj55XpJbyviGNGyscXX4AWEEAABfGb2ixu0+tYom8wZjavAjwggAAL4yekXNgS3SkS+kqFhp2reNqcGPCCMAAPjK6GGaimc9X6d9R7LEGVODHxFGAADwVUcYaaiU2k4M7nu3nZC2veLZD4EhGokwAgCA74YkSdYESW7p8BeD+94710stdsmW7pm8GgIIIwAA+MpkMm6oxttb5HrPg/tCQGj8FAAADDYjVtQ4DkpfvO3ZD5EhGokwAgBA/xixombrC5LbJaXnnuwEGxoIIwAA9MdgD9O43aeGaIL4oXjdIYwAANAfHWHk8G7J5Rr49/vyI+nQDinSKp17zcC/3yAijAAA0B/DxkrmKKmtSXJUD/z7fXyy4+qUqySrbeDfbxARRgAA6I+IKGn4eM/+QA/VtLdIW1/07IfYEI1EGAEAoP+8k1gHeEXNrrekE0eluFHS+EsG9r0MQBgBAKC/BmsSa8cQzczrJHPEwL6XAQgjAAD012CEkeOHpM//5tnPDL0hGokwAgBA/w1G47OtL0qudin1fGnklIF7HwMRRgAA6K+kiZ6vx2ukZvvAvMfHodlbpDPCCAAA/WW1SUNTPPv1u/3/+jVbPVtEtDT9Wv+/foAgjAAAcDYGsi18xcmJq5O/JcUO9//rBwjCCAAAZ2OgJrE62zzPopFCeohGIowAAHB2BiqM7P671HhIGjJCmpjv39cOMIQRAADOxkA1Put4KN6M6zzdXkMYYQQAgLPRcWfkyB7P0Io/NB2Rdm3w7Gfd4J/XDGCEEQAAzkZ8mhQVK7napKP7/fOa2/4sOVullBmeLcQRRgAAOBtms5R4st+Iv+aNdAzRhGjH1a/qVxhZtWqVMjIyZLValZubq82bN/d47ssvv6ycnBwlJCRoyJAhysrK0tNPP93vggEACDj+nMRat0P6slwyR0oz5p796wUBn8PIunXrVFRUpOXLl6u8vFyZmZkqKChQXV1dt+cPHz5c99xzj0pLS/XJJ5+osLBQhYWFeuutt866eAAAAoI/28J3dFyddLk0dMTZv14Q8DmMrFixQgsXLlRhYaGmTZum1atXKzY2VmvXru32/IsvvljXXHONpk6dqgkTJmjx4sWaOXOmNm3adNbFAwAQEPzV+MzllD452VskM/QnrnbwKYy0traqrKxM+fmn1jubzWbl5+ertLT0jNe73W6VlJRo586d+uY3v9njeS0tLXI4HF02AAACVudhGre7/6+z5x3p2EEpZpg0ucA/tQUBn8JIfX29nE6nkpOTuxxPTk5WTU1Nj9fZ7XYNHTpU0dHRuuqqq/Too4/qsssu6/H84uJi2Ww275aenu5LmQAADK7ECZJMUnOD1Fjf/9fx9haZK0Va/FFZUBiU1TRxcXGqqKjQli1bdN9996moqEjvvvtuj+cvWbJEdrvdu1VVVQ1GmQAA9E9UjJQwxrPf36GaZru04w3PfhgN0UhSpC8nJyUlKSIiQrW1tV2O19bWKiUlpcfrzGazJk70LHvKysrS9u3bVVxcrIsvvrjb8y0WiyyW8EmEAIAQkDRZatjvCSMZs32//tNXpPZmacQUKfU8/9cXwHy6MxIdHa3s7GyVlJR4j7lcLpWUlCgvL6/Pr+NyudTS0uLLWwMAENjOdkVNxxBN1o2SyeSfmoKET3dGJKmoqEgLFixQTk6OZs2apZUrV6qxsVGFhYWSpPnz5ystLU3FxcWSPPM/cnJyNGHCBLW0tGj9+vV6+umn9fjjj/v3JwEAwEhns6Lm8BdS1QeSySzNnOffuoKAz2Fk3rx5OnTokJYtW6aamhplZWVpw4YN3kmtlZWVMptP3XBpbGzUD3/4Qx04cEAxMTGaMmWKnnnmGc2bF36/bABACDubxmcf/8nzdcK/SHE9T3sIVSa3+2zWIA0Oh8Mhm80mu92u+Ph4o8sBAOB0xw9Jv50oySTdc9AzqbUvXC7pkZmSvUr63lpp+rUDWuZg6uvnN8+mAQDAH4YkSdYESW7PsEtf7ft/niBisUnnXDVQ1QU0wggAAP5gMp0aqjnswyTWjiGa6ddIUVb/1xUECCMAAPiLrytqWo5Jn73m2c+6aWBqCgKEEQAA/MXXFTWfvS61NUnDJ0ijLxi4ugIcYQQAAH/xdUVNxxBN1g1h11ukM8IIAAD+0nmYxuXq/dyj+zyTV2WSZl4/0JUFNMIIAAD+MmysZI7yDL0c+7L3cz9e5/k67ptSQng/EJYwAgCAv0REScPHe/Z7G6pxu6WPO7V/D3OEEQAA/Mk7ibWXFTWVpZ5hmuih0tQ5g1JWICOMAADgT32ZxNrxULxpV0vRQwa8pEBHGAEAwJ/OFEZam6RPX/XsZ90wKCUFOsIIAAD+dKbGZzv+KrUekxLGSmMuHLy6AhhhBAAAf0qa6Pl67KDU7Dj9+x1DNJk3SGY+hiXCCAAA/mW1SUNTPPtffUaNvVra865nPzO8e4t0RhgBAMDfelpR88nzktzS2NnS8HGDXlagIowAAOBv3U1idbulipPt3zOZuNoZYQQAAH/rLoxUl3mGbSJjpGnfMaauAEUYAQDA37obpql41vN12rcla/zg1xTAIo0uAACAkNNxZ+TwF5KzXXK1S9v+7DnGEM1pCCMAAPhbfJoUFet5YF7DfqnmE6nZ7jk+7ptGVxdwGKYBAMDfzGYp8WS/kfpdnXqLXC+ZI4yrK0ARRgAAGAgdQzX7Nkm7Szz7DNF0izACAMBA6AgjW/5bcjul0RecmtiKLggjAAAMhI7g0d7s+Zp1o3G1BDjCCAAAA6HjzogkRVikc79rXC0BjjACAMBASJwgyeTZn3KlFJNgZDUBjTACAMBAiIo5dXck62Zjawlw9BkBAGCgfO9Jz9LeSflGVxLQCCMAAAyUlBmeDb1imAYAABiKMAIAAAxFGAEAAIbqVxhZtWqVMjIyZLValZubq82bN/d47po1a/SNb3xDw4YN07Bhw5Sfn9/r+QAAILz4HEbWrVunoqIiLV++XOXl5crMzFRBQYHq6uq6Pf/dd9/VDTfcoHfeeUelpaVKT0/X5Zdfrurq6rMuHgAABD+T2+12+3JBbm6uLrjgAj322GOSJJfLpfT0dP3oRz/S3XfffcbrnU6nhg0bpscee0zz58/v03s6HA7ZbDbZ7XbFx8f7Ui4AADBIXz+/fboz0traqrKyMuXnn1ovbTablZ+fr9LS0j69RlNTk9ra2jR8+PAez2lpaZHD4eiyAQCA0ORTGKmvr5fT6VRycnKX48nJyaqpqenTa/z0pz9Vampql0DzVcXFxbLZbN4tPT3dlzIBAEAQGdTVNA888ICef/55vfLKK7JarT2et2TJEtntdu9WVVU1iFUCAIDB5FMH1qSkJEVERKi2trbL8draWqWkpPR67W9/+1s98MAD+vvf/66ZM2f2eq7FYpHFYvGlNAAAEKR8ujMSHR2t7OxslZSUeI+5XC6VlJQoLy+vx+seeugh/epXv9KGDRuUk5PT/2oBAEDI8fnZNEVFRVqwYIFycnI0a9YsrVy5Uo2NjSosLJQkzZ8/X2lpaSouLpYkPfjgg1q2bJmee+45ZWRkeOeWDB06VEOHDvXjjwIAAIKRz2Fk3rx5OnTokJYtW6aamhplZWVpw4YN3kmtlZWVMptP3XB5/PHH1draqu9973tdXmf58uX6+c9/fnbVAwCAoOdznxEj2O12JSQkqKqqij4jAAAECYfDofT0dDU0NMhms/V4ns93Roxw7NgxSWKJLwAAQejYsWO9hpGguDPicrn05ZdfKi4uTiaTyW+v25HYuONydvg9+ge/R//g9+gf/B79I9x/j263W8eOHVNqamqXKRxfFRR3Rsxms0aPHj1grx8fHx+W/5H4G79H/+D36B/8Hv2D36N/hPPvsbc7Ih0GtekZAADAVxFGAACAocI6jFgsFi1fvpxur2eJ36N/8Hv0D36P/sHv0T/4PfZNUExgBQAAoSus74wAAADjEUYAAIChCCMAAMBQhBEAAGCosA4jq1atUkZGhqxWq3Jzc7V582ajSwoqxcXFuuCCCxQXF6eRI0fq6quv1s6dO40uK+g98MADMplMuvPOO40uJehUV1fr5ptvVmJiomJiYjRjxgx9+OGHRpcVVJxOp5YuXapx48YpJiZGEyZM0K9+9Sux1qF3//jHPzRnzhylpqbKZDLp1Vdf7fJ9t9utZcuWadSoUYqJiVF+fr4+//xzY4oNQGEbRtatW6eioiItX75c5eXlyszMVEFBgerq6owuLWi89957WrRokf75z39q48aNamtr0+WXX67GxkajSwtaW7Zs0e9//3vNnDnT6FKCztGjRzV79mxFRUXpzTff1GeffaaHH35Yw4YNM7q0oPLggw/q8ccf12OPPabt27frwQcf1EMPPaRHH33U6NICWmNjozIzM7Vq1apuv//QQw/pd7/7nVavXq0PPvhAQ4YMUUFBgZqbmwe50gDlDlOzZs1yL1q0yPtnp9PpTk1NdRcXFxtYVXCrq6tzS3K/9957RpcSlI4dO+aeNGmSe+PGje6LLrrIvXjxYqNLCio//elP3V//+teNLiPoXXXVVe7vf//7XY5997vfdd90000GVRR8JLlfeeUV759dLpc7JSXF/Zvf/MZ7rKGhwW2xWNx/+tOfDKgw8ITlnZHW1laVlZUpPz/fe8xsNis/P1+lpaUGVhbc7Ha7JGn48OEGVxKcFi1apKuuuqrLf5fou9dff105OTmaO3euRo4cqfPOO09r1qwxuqygc+GFF6qkpES7du2SJH388cfatGmTrrjiCoMrC1579+5VTU1Nl/+3bTabcnNz+cw5KSgelOdv9fX1cjqdSk5O7nI8OTlZO3bsMKiq4OZyuXTnnXdq9uzZmj59utHlBJ3nn39e5eXl2rJli9GlBK09e/bo8ccfV1FRkX72s59py5Yt+vd//3dFR0drwYIFRpcXNO6++245HA5NmTJFERERcjqduu+++3TTTTcZXVrQqqmpkaRuP3M6vhfuwjKMwP8WLVqkbdu2adOmTUaXEnSqqqq0ePFibdy4UVar1ehygpbL5VJOTo7uv/9+SdJ5552nbdu2afXq1YQRH7zwwgt69tln9dxzz+ncc89VRUWF7rzzTqWmpvJ7xIAJy2GapKQkRUREqLa2tsvx2tpapaSkGFRV8Lrjjjv017/+Ve+8845Gjx5tdDlBp6ysTHV1dTr//PMVGRmpyMhIvffee/rd736nyMhIOZ1Oo0sMCqNGjdK0adO6HJs6daoqKysNqig4/cd//IfuvvtuXX/99ZoxY4ZuueUW3XXXXSouLja6tKDV8bnCZ07PwjKMREdHKzs7WyUlJd5jLpdLJSUlysvLM7Cy4OJ2u3XHHXfolVde0dtvv61x48YZXVJQuvTSS7V161ZVVFR4t5ycHN10002qqKhQRESE0SUGhdmzZ5+2tHzXrl0aO3asQRUFp6amJpnNXT8aIiIi5HK5DKoo+I0bN04pKSldPnMcDoc++OADPnNOCtthmqKiIi1YsEA5OTmaNWuWVq5cqcbGRhUWFhpdWtBYtGiRnnvuOb322muKi4vzjn3abDbFxMQYXF3wiIuLO22ezZAhQ5SYmMj8Gx/cdddduvDCC3X//ffruuuu0+bNm/XEE0/oiSeeMLq0oDJnzhzdd999GjNmjM4991x99NFHWrFihb7//e8bXVpAO378uHbv3u398969e1VRUaHhw4drzJgxuvPOO/XrX/9akyZN0rhx47R06VKlpqbq6quvNq7oQGL0ch4jPfroo+4xY8a4o6Oj3bNmzXL/85//NLqkoCKp2+1//ud/jC4t6LG0t3/+8pe/uKdPn+62WCzuKVOmuJ944gmjSwo6DofDvXjxYveYMWPcVqvVPX78ePc999zjbmlpMbq0gPbOO+90+/fhggUL3G63Z3nv0qVL3cnJyW6LxeK+9NJL3Tt37jS26ABicrtpqwcAAIwTlnNGAABA4CCMAAAAQxFGAACAoQgjAADAUIQRAABgKMIIAAAwFGEEAAAYijACAAAMRRgBAACGIowAAABDEUYAAIChCCMAAMBQ/x8cK1+JyF08UAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_train)\n",
    "plt.plot(f1_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********: 0\n",
      "39/39 [==============================] - 0s 3ms/step\n",
      "*********: 1\n",
      "39/39 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2bf472fd0>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = some_pred(training_split, 2)\n",
    "ans = majority(data)\n",
    "ConfusionMatrixDisplay.from_predictions(train_result,ans,cmap='Greens')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********: 0\n",
      "11/11 [==============================] - 0s 5ms/step\n",
      "*********: 1\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "table_test = pd.read_table('./1663769555_8653905_test.txt', names=['sequence'])\n",
    "unlabeled_test = vectorizer_best.transform(table_test.sequence).toarray()\n",
    "predicted_data = majority(some_pred(unlabeled_test, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "350"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "import csv\n",
    "outfile = open('./results.csv','w')\n",
    "out = csv.writer(outfile)\n",
    "out.writerows(map(lambda x: [x], predicted_data))\n",
    "outfile.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}